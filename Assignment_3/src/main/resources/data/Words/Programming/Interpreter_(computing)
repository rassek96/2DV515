interpreter computing from wikipedia free encyclopedia jump navigation search program execution general concepts runtime system runtime library executable compiler interpreter virtual machine intermediate representation ir source code object code bytecode machine code compilation strategies just-in-time jit o tracing just-in-time ahead-of-time aot transcompilation recompilation notable runtimes android runtime art common language runtime clr crt0 java virtual machine jvm nodejs zend engine notable compilers & toolchains llvm gnu compiler collection gcc v t e computer science interpreter computer program that directly executes ie performs instructions written programming scripting language without previously compiling them into machine language program interpreter generally uses one following strategies for program execution parse source code perform its behavior directly translate source code into some efficient intermediate representation immediately execute this explicitly execute stored precompiled code made by compiler which part interpreter system early versions lisp programming language dartmouth basic would be examples first type perl python matlab ruby are examples second while ucsd pascal example third type source programs are compiled ahead time stored machine independent code which then linked at run-time executed by interpreter and/or compiler for jit systems some systems such smalltalk contemporary versions basic java may also combine two three intepreters various types have also been constructed for many languages traditionally associated with compilation such algol fortran cobol c/c++ while interpretation compilation are two main means by which programming languages are implemented they are not mutually exclusive most interpreting systems also perform some translation work just like compilers terms interpreted language compiled language signify that canonical implementation that language interpreter compiler respectively high level language ideally abstraction independent particular implementations contents history compilers versus interpreters o development cycle o distribution o efficiency o regression variations o bytecode interpreters o threaded code interpreters o abstract syntax tree interpreters o just-in-time compilation o self-interpreter applications punched card interpreter see also notes references external links history first interpreted high-level language was lisp lisp was first implemented by steve russell on ibm computer russell had read john mccarthy's paper realized mccarthy's surprise that lisp eval function could be implemented machine code result was working lisp interpreter which could be used run lisp programs more properly evaluate lisp expressions compilers versus interpreters illustration linking process object files static libraries are assembled into new library executable programs written high level language are either directly executed by some kind interpreter converted into machine code by compiler assembler linker for cpu execute while compilers assemblers generally produce machine code directly executable by computer hardware they can often optionally produce intermediate form called object code this basically same machine specific code but augmented with symbol table with names tags make executable blocks modules identifiable relocatable compiled programs will typically use building blocks functions kept library such object code modules linker used combine pre-made library files with object files application form single executable file object files that are used generate executable file are thus often produced at different times sometimes even by different languages capable generating same object format simple interpreter written low level language eg assembly may have similar machine code blocks implementing functions high level language stored executed when function's entry look up table points that code however interpreter written high level language typically uses another approach such generating then walking parse tree by generating executing intermediate software-defined instructions both thus both compilers interpreters generally turn source code text files into tokens both may may not generate parse tree both may generate immediate instructions for stack machine quadruple code by other means basic difference that compiler system including built separate linker generates stand-alone machine code program while interpreter system instead performs actions described by high level program compiler can thus make almost all conversions from source code semantics machine level once for all ie until program has be changed while interpreter has do some this conversion work every time statement function executed however efficient interpreter much translation work including analysis types similar factored out done only first time program module function even statement run thus quite akin how compiler works however compiled program still runs much faster under most circumstances part because compilers are designed optimize code may be given ample time for this this especially true for simpler high level languages without much dynamic data structures checks typing traditional compilation executable output linkers exe files dll files library see picture typically relocatable when run under general operating system much like object code modules are but with difference that this relocation done dynamically at run time ie when program loaded for execution on other hand compiled linked programs for small embedded systems are typically statically allocated often hard coded nor flash memory there are often no secondary storage no operating system this sense historically most interpreter-systems have had self-contained editor built this becoming more common also for compilers then often called ide although some programmers prefer use editor their choice run compiler linker other tools manually historically compilers predate interpreters because hardware at that time could not support both interpreter interpreted code typical batch environment time limited advantages interpretation development cycle during software development cycle programmers make frequent changes source code when using compiler each time change made source code they must wait for compiler translate altered source files link all binary code files together before program can be executed larger program longer wait by contrast programmer using interpreter does lot less waiting interpreter usually just needs translate code being worked on intermediate representation not translate at all thus requiring much less time before changes can be tested effects are evident upon saving source code reloading program compiled code generally less readily debugged editing compiling linking are sequential processes that have be conducted proper sequence with proper set commands for this reason many compilers also have executive aid known make file program make file lists compiler linker command lines program source code files but might take simple command line menu input eg make which selects third group set instructions then issues commands compiler linker feeding specified source code files distribution compiler converts source code into binary instruction for specific processor's architecture thus making less portable this conversion made just once on developer's environment after that same binary can be distributed user's machines where can be executed without further translation cross compiler can generate binary code for user machine even if has different processor than machine where code compiled interpreted program can be distributed source code needs be translated each final machine which takes more time but makes program distribution independent machine's architecture however portability interpreted source code dependent on target machine actually having suitable interpreter if interpreter needs be supplied along with source overall installation process more complex than delivery monolithic executable since interpreter itself part what need be installed fact that interpreted code can easily be read copied by humans can be concern from point view copyright however various systems encryption obfuscation exist delivery intermediate code such bytecode has similar effect obfuscation but bytecode could be decoded with decompiler disassembler efficiency main disadvantage interpreters that interpreted program typically runs slower than if had been compiled difference speeds could be tiny great often order magnitude sometimes more generally takes longer run program under interpreter than run compiled code but can take less time interpret than total time required compile run this especially important when prototyping testing code when edit-interpret-debug cycle can often be much shorter than edit-compile-run-debug cycle interpreting code slower than running compiled code because interpreter must analyze each statement program each time executed then perform desired action whereas compiled code just performs action within fixed context determined by compilation this run-time analysis known interpretive overhead access variables also slower interpreter because mapping identifiers storage locations must be done repeatedly at run-time rather than at compile time there are various compromises between development speed when using interpreter execution speed when using compiler some systems such some lisps allow interpreted compiled code call each other share variables this means that once routine has been tested debugged under interpreter can be compiled thus benefit from faster execution while other routines are being developed many interpreters do not execute source code stands but convert into some more compact internal form many basic interpreters replace keywords with single byte tokens which can be used find instruction jump table few interpreters such pbasic interpreter achieve even higher levels program compaction by using bit-oriented rather than byte-oriented program memory structure where commands tokens occupy perhaps bits nominally 16-bit constants are stored variable-length code requiring bits address operands include bit offset many basic interpreters can store read back their own tokenized internal representation toy c expression interpreter // data types for abstract syntax tree enum kind { kvarkconstksumkdiffkmultkdivkpluskminusknot } struct variable { int memory } struct constant { int value } struct unaryoperation { struct node right } struct binaryoperation { struct node left right } struct node { enum kind kind union expression { struct variable variable struct constant constant struct binaryoperation binary struct unaryoperation unary } e } // interpreter procedure int executeintexpressionconst struct node n { int leftvalue rightvalue switch n->kind { case kvar return n->evariablememory case kconst return n->econstantvalue case ksum case kdiff case kmult case kdiv leftvalue = executeintexpressionn->ebinaryleft rightvalue = executeintexpressionn->ebinaryright switch n->kind { case ksum return leftvalue + rightvalue case kdiff return leftvalue - rightvalue case kmult return leftvalue rightvalue case kdiv if rightvalue == exceptiondivision by zero // doesn't return return leftvalue / rightvalue } case kplus case kminus case knot rightvalue = executeintexpressionn->eunaryright switch n->kind { case kplus return + rightvalue case kminus return - rightvalue case knot return rightvalue } default exceptioninternal error illegal expression kind } } interpreter might well use same lexical analyzer parser compiler then interpret resulting abstract syntax tree example data type definitions for latter toy interpreter for syntax trees obtained from c expressions are shown box regression interpretation cannot be used sole method execution even though interpreter can itself be interpreted so on directly executed program needed somewhere at bottom stack because code being interpreted not by definition same machine code that cpu can execute variations bytecode interpreters main article bytecode there spectrum possibilities between interpreting compiling depending on amount analysis performed before program executed for example emacs lisp compiled bytecode which highly compressed optimized representation lisp source but not machine code therefore not tied any particular hardware this compiled code then interpreted by bytecode interpreter itself written c compiled code this case machine code for virtual machine which implemented not hardware but bytecode interpreter byte code interpreter each instruction starts with byte therefore byte code interpreters have up instructions although not all may be used some byte codes may take multiple bytes may be arbitrarily complicated control tables - that do not necessarily ever need pass through compiling phase - dictate appropriate algorithmic control flow via customized interpreters similar fashion bytecode interpreters threaded code interpreters main article threaded code threaded code interpreters are similar byte code interpreters but instead bytes they use pointers each instruction word that points function instruction sequence possibly followed by parameter threaded code interpreter either loops fetching instructions calling functions they point fetches first instruction jumps every instruction sequence ends with fetch jump next instruction unlike byte code there no effective limit on number different instructions other than available memory address space classic example threaded code forth code used open firmware systems source language compiled into f code bytecode which then interpreted by virtual machine abstract syntax tree interpreters main article abstract syntax tree spectrum between interpreting compiling another approach transform source code into optimized abstract syntax tree ast then execute program following this tree structure use generate native code just-in-time this approach each sentence needs be parsed just once advantage over bytecode ast keeps global program structure relations between statements which lost bytecode representation when compressed provides more compact representation thus using ast has been proposed better intermediate format for just-in-time compilers than bytecode also allows system perform better analysis during runtime however for interpreters ast causes more overhead than bytecode interpreter because nodes related syntax performing no useful work less sequential representation requiring traversal more pointers overhead visiting tree just-in-time compilation main article just-in-time compilation further blurring distinction between interpreters byte-code interpreters compilation just-in-time compilation jit technique which intermediate representation compiled native machine code at runtime this confers efficiency running native code at cost startup time increased memory use when bytecode ast first compiled adaptive optimization complementary technique which interpreter profiles running program compiles its most frequently executed parts into native code both techniques are few decades old appearing languages such smalltalk 1980s just-in-time compilation has gained mainstream attention amongst language implementers recent years with java net framework most modern javascript implementations matlab now including jits self-interpreter main article meta-circular interpretation self-interpreter programming language interpreter written programming language which can interpret itself example basic interpreter written basic self-interpreters are related self-hosting compilers if no compiler exists for language be interpreted creating self-interpreter requires implementation language host language which may be another programming language assembler by having first interpreter such this system bootstrapped new versions interpreter can be developed language itself was this way that donald knuth developed tangle interpreter for language web industrial standard tex typesetting system defining computer language usually done relation abstract machine so-called operational semantics mathematical function denotational semantics language may also be defined by interpreter which semantics host language given definition language by self-interpreter not well-founded cannot define language but self-interpreter tells reader about expressiveness elegance language also enables interpreter interpret its source code first step towards reflective interpreting important design dimension implementation self-interpreter whether feature interpreted language implemented with same feature interpreter's host language example whether closure lisp-like language implemented using closures interpreter language implemented manually with data structure explicitly storing environment more features implemented by same feature host language less control programmer interpreter has different behavior for dealing with number overflows cannot be realized if arithmetic operations are delegated corresponding operations host language some languages have elegant self-interpreter such lisp prolog much research on self-interpreters particularly reflective interpreters has been conducted scheme programming language dialect lisp general however any turing-complete language allows writing its own interpreter lisp such language because lisp programs are lists symbols other lists xslt such language because xslt programs are written xml sub-domain meta-programming writing domain-specific languages dsls clive gifford introduced measure quality self-interpreter eigenratio limit ratio between computer time spent running stack n self-interpreters time spent run stack n−1 self-interpreters n goes infinity this value does not depend on program being run book structure interpretation computer programs presents examples meta-circular interpretation for scheme its dialects other examples languages with self-interpreter are forth pascal applications interpreters are frequently used execute command languages glue languages since each operator executed command language usually invocation complex routine such editor compiler self-modifying code can easily be implemented interpreted language this relates origins interpretation lisp artificial intelligence research virtualization machine code intended for one hardware architecture can be run on another using virtual machine which essentially interpreter sandboxing interpreter virtual machine not compelled actually execute all instructions source code processing particular can refuse execute code that violates any security constraints operating under punched card interpreter term interpreter often referred piece unit record equipment that could read punched cards print characters human-readable form on card ibm numeric interpreter ibm alphabetic interpreter are typical examples from respectively see also command-line interpreter compiled language dynamic compilation interpreted language meta-circular evaluator partial evaluation self-interpreter notes references this sense cpu also interpreter machine instructions although this scheme combining strategy was used implement certain basic interpreters already 1970s such efficient basic interpreter abc for instance according what reported by paul graham hackers & painters p mccarthy said steve russell said look why don't i program this eval i said him ho ho you're confusing theory with practice this eval intended for reading not for computing but he went ahead did that he compiled eval my paper into ibm machine code fixing bug then advertised this lisp interpreter which certainly was so at that point lisp had essentially form that has today why was first compiler written before first interpreter ars technica retrieved november theodore h romer dennis lee geoffrey m voelker alec wolman wayne wong jean-loup baer brian n bershad henry m levy structure performance interpreters terence parr johannes luber difference between compilers interpreters ast intermediate representations lambda ultimate forum tree-based alternative java byte-codes thomas kistler michael franz surfin' safari - blog archive » announcing squirrelfish webkitorg retrieved on l deutsch schiffman efficient implementation smalltalk-80 system proceedings 11th popl symposium external links ibm card interpreters page at columbia university theoretical foundations for practical 'totally functional programming' chapter especially doctoral dissertation tackling problem formalising what interpreter short animation explaining key conceptual difference between interpreters compilers v t e major fields computer science note this template roughly follows acm computing classification hardware printed circuit board peripheral integrated circuit very-large-scale integration energy consumption electronic design automation computer systems organization computer architecture embedded system real-time computing dependability networks network architecture network protocol network components network scheduler network performance evaluation network service software organization interpreter middleware virtual machine operating system software quality software notations tools programming paradigm programming language compiler domain-specific language modeling language software framework integrated development environment software configuration management software library software repository software development software development process requirements analysis software design software construction software deployment software maintenance programming team open-source model theory computation model computation formal language automata theory computational complexity theory logic semantics algorithms algorithm design analysis algorithms randomized algorithm computational geometry mathematics computing discrete mathematics probability statistics mathematical software information theory mathematical analysis numerical analysis information systems database management system information storage systems enterprise information system social information systems geographic information system decision support system process control system multimedia information system data mining digital library computing platform digital marketing world wide web information retrieval security cryptography formal methods security services intrusion detection system hardware security network security information security application security human–computer interaction interaction design social computing ubiquitous computing visualization accessibility concurrency concurrent computing parallel computing distributed computing multithreading multiprocessing artificial intelligence natural language processing knowledge representation reasoning computer vision automated planning scheduling search methodology control method philosophy artificial intelligence distributed artificial intelligence machine learning supervised learning unsupervised learning reinforcement learning multi-task learning machine learning algorithms cross-validation graphics animation rendering image manipulation graphics processing unit mixed reality virtual reality image compression solid modeling applied computing e-commerce enterprise software computational mathematics computational physics computational chemistry computational biology computational social science computational engineering computational healthcare digital art electronic publishing cyberwarfare electronic voting video game word processing operations research educational technology document management computer science portal authority control lccn sh85067496 gnd 4162129-3 bnf cb11938287v data this article based on material taken from free on-line dictionary computing prior november incorporated under relicensing terms gfdl version later retrieved from https//enwikipediaorg/w/indexphptitle=interpretercomputing&oldid=752093170 categories interpreters computing programming language implementation hidden categories all articles with unsourced statements articles with unsourced statements from january articles with unsourced statements from april articles with unsourced statements from february wikipedia articles with lccn identifiers wikipedia articles with gnd identifiers wikipedia articles with bnf identifiers navigation menu personal tools not logged talk contributions create account log namespaces article talk variants views read edit view history more search navigation main page contents featured content current events random article donate wikipedia wikipedia store interaction help about wikipedia community portal recent changes contact page tools what links here related changes upload file special pages permanent link page information wikidata item cite this page print/export create book download pdf printable version languages العربية azərbaycanca বাংলা български bosanski català čeština dansk deutsch eesti ελληνικά español euskara فارسی français gaeilge galego 한국어 հայերեն hrvatski ilokano bahasa indonesia íslenska italiano עברית кыргызча lietuvių magyar bahasa melayu mirandés nederlands 日本語 norsk bokmål ਪੰਜਾਬੀ polski português română русский scots simple english slovenčina slovenščina српски / srpski suomi svenska தமிழ் ไทย türkçe українська tiếng việt 中文 edit links this page was last modified on november at text available under creative commons attribution-sharealike license additional terms may apply by using this site you agree terms use privacy policy wikipedia® registered trademark wikimedia foundation inc non-profit organization privacy policy about wikipedia disclaimers contact wikipedia developers cookie statement mobile view 