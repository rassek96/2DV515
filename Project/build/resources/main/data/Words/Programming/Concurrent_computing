concurrent computing from wikipedia free encyclopedia jump navigation search for more theoretical discussion see concurrency computer science programming paradigms action agent-oriented array-oriented automata-based concurrent computing o relativistic programming data-driven declarative contrast imperative o constraint + constraint logic concurrent constraint logic o dataflow + flow-based + cell-oriented spreadsheets + reactive o functional + functional logic + purely functional o logic + abductive logic + answer set + concurrent logic + functional logic + inductive logic dynamic end-user programming event-driven o service-oriented o time-driven expression-oriented feature-oriented function-level contrast value-level generic imperative contrast declarative o literate o procedural inductive programming language-oriented o natural language programming o discipline-specific o domain-specific o grammar-oriented + dialecting o intentional metaprogramming o automatic o reflective + attribute-oriented o homoiconic o template + policy-based non-structured contrast structured o array nondeterministic parallel computing o process-oriented point-free style o concatenative semantic structured contrast non-structured o block-structured o modular contrast monolithic o object-oriented + actor-based + class-based + concurrent + prototype-based + by separation concerns aspect-oriented role-oriented subject-oriented o recursive value-level contrast function-level probabilistic concept v t e concurrent computing form computing which several computations are executed during overlapping time periods—concurrently—instead sequentially one completing before next starts this property system—this may be individual program computer network—and there separate execution point thread control for each computation process concurrent system one where computation can advance without waiting for all other computations complete where more than one computation can advance at same time programming paradigm concurrent computing form modular programming namely factoring overall computation into subcomputations that may be executed concurrently pioneers field concurrent computing include edsger dijkstra per brinch hansen car hoare contents introduction o coordinating access shared resources o advantages models implementation o interaction communication history prevalence languages supporting see also notes references further reading external links introduction see also parallel computing concurrent computing related but distinct from parallel computing though these concepts are frequently confused both can be described multiple processes executing during same period time parallel computing execution occurs at same physical instant for example on separate processors multi-processor machine with goal speeding up computations—parallel computing impossible on one-core single processor only one computation can occur at any instant during any single clock cycle by contrast concurrent computing consists process lifetimes overlapping but execution need not happen at same instant goal here model processes outside world that happen concurrently such multiple clients accessing server at same time structuring software systems composed multiple concurrent communicating parts can be useful for tackling complexity regardless whether parts can be executed parallel for example concurrent processes can be executed on one core by interleaving execution steps each process via time-sharing slices only one process runs at time if does not complete during its time slice paused another process begins resumes then later original process resumed this way multiple processes are part-way through execution at single instant but only one process being executed at that instant concurrent computations may be executed parallel for example by assigning each process separate processor processor core distributing computation across network but general languages tools techniques for parallel programming may not be suitable for concurrent programming vice versa exact timing when tasks concurrent system are executed depend on scheduling tasks need not always be executed concurrently for example given two tasks t1 t2 t1 may be executed finished before t2 vice versa serial sequential t1 t2 may be executed alternately serial concurrent t1 t2 may be executed simultaneously at same instant time parallel concurrent word sequential used antonym for both concurrent parallel when these are explicitly distinguished concurrent/sequential parallel/serial are used opposing pairs schedule which tasks execute one at time serially no parallelism without interleaving sequentially no concurrency no task begins until prior task ends called serial schedule set tasks that can be scheduled serially serializable which simplifies concurrency control coordinating access shared resources main challenge designing concurrent programs concurrency control ensuring correct sequencing interactions communications between different computational executions coordinating access resources that are shared among executions potential problems include race conditions deadlocks resource starvation for example consider following algorithm make withdrawals from checking account represented by shared resource balance bool withdrawint withdrawal { if balance >= withdrawal { balance -= withdrawal return true } return false } suppose balance = two concurrent threads make calls withdraw300 withdraw350 if line both operations executes before line both operations will find that balance >= withdrawal evaluates true execution will proceed subtracting withdrawal amount however since both processes perform their withdrawals total amount withdrawn will end up being more than original balance these sorts problems with shared resources need use concurrency control non-blocking algorithms because concurrent systems rely on use shared resources including communication media concurrent computing general needs use some form arbiter somewhere implementation mediate access these resources unfortunately while many solutions exist problem conflict over one resource many those solutions have their own concurrency problems such deadlock when more than one resource involved advantages this section does not cite any sources please help improve this section by adding citations reliable sources unsourced material may be challenged removed december learn how when remove this template message increased program throughput—parallel execution concurrent program allows number tasks completed given time increase high responsiveness for input/output—input/output-intensive programs mostly wait for input output operations complete concurrent programming allows time that would be spent waiting be used for another task more appropriate program structure—some problems problem domains are well-suited representation concurrent tasks processes models there are several models concurrent computing which can be used understand analyze concurrent systems these models include actor model o object-capability model for security petri nets process calculi such o ambient calculus o calculus communicating systems ccs o communicating sequential processes csp o π-calculus o join-calculus input/output automaton implementation ] this section needs expansion you can help by adding february number different methods can be used implement concurrent programs such implementing each computational execution operating system process implementing computational processes set threads within single operating system process interaction communication some concurrent computing systems communication between concurrent components hidden from programmer eg by using futures while others must be handled explicitly explicit communication can be divided into two classes shared memory communication concurrent components communicate by altering contents shared memory locations exemplified by java c this style concurrent programming usually needs use some form locking eg mutexes semaphores monitors coordinate between threads program that properly implements any these said be thread-safe message passing communication concurrent components communicate by exchanging messages exemplified by scala erlang occam exchange messages may be carried out asynchronously may use synchronous rendezvous style which sender blocks until message received asynchronous message passing may be reliable unreliable sometimes referred send pray message-passing concurrency tends be far easier reason about than shared-memory concurrency typically considered more robust form concurrent programming wide variety mathematical theories understand analyze message-passing systems are available including actor model various process calculi message passing can be efficiently implemented via symmetric multiprocessing with without shared memory cache coherence shared memory message passing concurrency have different performance characteristics typically although not always per-process memory overhead task switching overhead lower message passing system but overhead message passing greater than for procedure call these differences are often overwhelmed by other performance factors history concurrent computing developed out earlier work on railroads telegraphy from 19th early 20th century some terms date this period such semaphores these arose address question how handle multiple trains on same railroad system avoiding collisions maximizing efficiency how handle multiple transmissions over given set wires improving efficiency such via time-division multiplexing 1870s academic study concurrent algorithms started 1960s with dijkstra credited with being first paper this field identifying solving mutual exclusion prevalence concurrency pervasive computing occurring from low-level hardware on single chip world-wide networks examples follow at programming language level channel coroutine futures promises at operating system level computer multitasking including both cooperative multitasking preemptive multitasking o time-sharing which replaced sequential batch processing jobs with concurrent use system process thread at network level networked systems are generally concurrent by their nature they consist separate devices languages supporting concurrent programming languages are programming languages that use language constructs for concurrency these constructs may involve multi-threading support for distributed computing message passing shared resources including shared memory futures promises such languages are sometimes described concurrency oriented languages concurrency oriented programming languages copl today most commonly used programming languages that have specific constructs for concurrency are java c both these languages fundamentally use shared-memory concurrency model with locking provided by monitors although message-passing models can have been implemented on top underlying shared-memory model languages that use message-passing concurrency model erlang probably most widely used industry at present many concurrent programming languages have been developed more research languages eg pict rather than languages for production use however languages such erlang limbo occam have seen industrial use at various times last years languages which concurrency plays important role include ada—general purpose with native support for message passing monitor based concurrency alef—concurrent with threads message passing for system programming early versions plan from bell labs alice—extension standard ml adds support for concurrency via futures ateji px—extension java with parallel primitives inspired from π-calculus axum—domain specific concurrent based on actor model net common language runtime using c-like syntax c++—stdthread cω c omega—for research extends c uses asynchronous communication c—supports concurrent computing since version using lock yield async await keywords clojure—modern lisp for jvm concurrent clean—functional programming similar haskell concurrent collections cnc—achieves implicit parallelism independent memory model by explicitly defining flow data control concurrent haskell—lazy pure functional language operating concurrent processes on shared memory concurrent ml—concurrent extension standard ml concurrent pascal—by per brinch hansen curry d—multi-paradigm system programming language with explicit support for concurrent programming actor model e—uses promises preclude deadlocks ecmascript—promises available various libraries proposed for inclusion standard ecmascript eiffel—through its scoop mechanism based on concepts design by contract elixir—dynamic functional meta-programming aware language running on erlang vm erlang—uses asynchronous message passing with nothing shared faust—real-time functional for signal processing compiler provides automatic parallelization via openmp specific work-stealing scheduler fortran—coarrays do concurrent are part fortran standard go—for system programming with concurrent programming model based on csp hume—functional concurrent for bounded space time environments where automata processes are described by synchronous channels patterns message passing io—actor-based concurrency janus—features distinct askers tellers logical variables bag channels purely declarative java—thread class runnable interface javascript—via web workers browser environment promises callbacks jocaml—concurrent distributed channel based extension ocaml implements join-calculus processes join java—concurrent based on java language joule—dataflow-based communicates by message passing joyce—concurrent teaching built on concurrent pascal with features from csp by per brinch hansen labview—graphical dataflow functions are nodes graph data wires between nodes includes object-oriented language limbo—relative alef for system programming inferno operating system multilisp—scheme variant extended support parallelism modula-2—for system programming by n wirth successor pascal with native support for coroutines modula-3—modern member algol family with extensive support for threads mutexes condition variables newsqueak—for research with channels first-class values predecessor alef nodejs—a server-side runtime environment for javascript occam—influenced heavily by communicating sequential processes csp o occam-π—a modern variant occam which incorporates ideas from milner's π-calculus orc—heavily concurrent nondeterministic based on kleene algebra oz-mozart—multiparadigm supports shared-state message-passing concurrency futures parasail—object-oriented parallel free pointers race conditions pict—essentially executable implementation milner's π-calculus perl with anyevent coro python with twisted greenlet gevent reia—uses asynchronous message passing between shared-nothing objects red/system—for system programming based on rebol ruby with concurrent ruby celluloid rust—for system programming focus on massive concurrency using message-passing with move semantics shared immutable memory shared mutable memory that provably free race conditions salsa—actor-based with token-passing join first-class continuations for distributed computing over internet scala—general purpose designed express common programming patterns concise elegant type-safe way sequencel—general purpose functional main design objectives are ease programming code clarity-readability automatic parallelization for performance on multicore hardware provably free race conditions sr—for research stackless python stratifiedjs—combinator-based concurrency based on javascript superpascal—concurrent for teaching built on concurrent pascal joyce by per brinch hansen unicon—for research termite scheme—adds erlang-like concurrency scheme tnsdl—for developing telecommunication exchanges uses asynchronous message passing vhsic hardware description language vhdl—ieee std-1076 xc—concurrency-extended subset c language developed by xmos based on communicating sequential processes built-in constructs for programmable i/o many other languages provide support for concurrency form libraries at levels roughly comparable with above list see also list important publications concurrent parallel distributed computing chu space critical section flow-based programming multitasking parallel computing ptolemy project race condition sheaf mathematics software transactional memory transaction processing java concurrentmap notes this discounting parallelism internal processor core such pipelining vectorized instructions one-core one-processor machine may be capable some parallelism such with coprocessor but processor alone not references this article needs additional citations for verification please help improve this article by adding citations reliable sources unsourced material may be challenged removed february learn how when remove this template message operating system concepts 9th edition abraham silberschatz chapter threads b concurrency not parallelism waza conference jan rob pike slides video parallelism vs concurrency haskell wiki schneider fred b on concurrent programming springer isbn b ben-ari mordechai principles concurrent distributed programming 2nd ed addison-wesley isbn 978-0-321-31283-9 patterson & hennessy p podc influential paper award acm symposium on principles distributed computing retrieved armstrong joe making reliable distributed systems presence software errors missing empty |url= help |access-date= requires |url= help blum ben typesafe shared mutable state retrieved patterson david hennessy john l computer organization design hardware/software interface morgan kaufmann series computer architecture design ed morgan kaufmann isbn 978-0-12407886-4 further reading dijkstra e w solution problem concurrent programming control communications acm doi 101145/365559365617 herlihy maurice art multiprocessor programming morgan kaufmann isbn 978-0123705914 downey allen b little book semaphores pdf green tea press isbn 1-4414-1868-7 filman robert e daniel p friedman coordinated computing tools techniques for distributed software new york mcgraw-hill p isbn 0-07-022439-0 leppäjärvi jouni pragmatic historically oriented survey on universality synchronization primitives pdf university oulu taubenfeld gadi synchronization algorithms concurrent programming pearson / prentice hall p isbn 0-13-197259-6 external links concurrent systems virtual library v t e concurrent computing general concurrency concurrency control process calculi csp ccs acp lotos π-calculus ambient calculus api-calculus pepa join-calculus category concurrent computing v t e types programming languages actor-based array aspect-oriented class-based concatenative concurrent data-structured dataflow declarative domain-specific dynamic esoteric event-driven extensible functional imperative logic macro metaprogramming+multi-paradigm object-based object-oriented pipeline procedural prototype-based reflective rule-based scripting synchronous templating assembly compiled interpreted machine low-level high-level very high-level first generation second generation third generation fourth generation fifth generation non-english-based visual retrieved from https//enwikipediaorg/w/indexphptitle=concurrentcomputing&oldid=746231163 categories operating system technology concurrent computing edsger w dijkstra hidden categories pages using web citations with no url pages using citations with accessdate no url articles needing additional references from december all articles needing additional references articles be expanded from february all articles be expanded articles using small message boxes all articles with unsourced statements articles with unsourced statements from may articles with unsourced statements from august articles needing additional references from february navigation menu personal tools not logged talk contributions create account log namespaces article talk variants views read edit view history more search navigation main page contents featured content current events random article donate wikipedia wikipedia store interaction help about wikipedia community portal recent changes contact page tools what links here related changes upload file special pages permanent link page information wikidata item cite this page print/export create book download pdf printable version languages български català deutsch español euskara français 한국어 nederlands 日本語 norsk bokmål polski português русский српски / srpski suomi 中文 edit links this page was last modified on october at text available under creative commons attribution-sharealike license additional terms may apply by using this site you agree terms use privacy policy wikipedia® registered trademark wikimedia foundation inc non-profit organization privacy policy about wikipedia disclaimers contact wikipedia developers cookie statement mobile view 