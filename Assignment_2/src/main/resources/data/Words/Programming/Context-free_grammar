context-free grammar from wikipedia free encyclopedia jump navigation search this article needs additional citations for verification please help improve this article by adding citations reliable sources unsourced material may be challenged removed february learn how when remove this template message context-free grammar cfg term used formal language theory describe certain type formal grammar context-free grammar set production rules that describe all possible strings given formal language production rules are simple replacements for example rule → α {\displaystyle a\ \to \ \alpha } replaces {\displaystyle a} with α {\displaystyle \alpha } there can be multiple replacement rules for any given value for example → α {\displaystyle a\ \to \ \alpha } → β {\displaystyle a\ \to \ \beta } means that {\displaystyle a} can be replaced with either α {\displaystyle \alpha } β {\displaystyle \beta } context-free grammars all rules are one one one many one none these rules can be applied regardless context left-hand side production rule also always nonterminal symbol this means that symbol does not appear resulting formal language so our case our language contains letters α {\displaystyle \alpha } β {\displaystyle \beta } but not {\displaystyle a} rules can also be applied reverse check if string grammatically correct according grammar here example context-free grammar which describes all two-letter strings containing letters α {\displaystyle \alpha } β {\displaystyle \beta } s → {\displaystyle s\ \to \ aa} → α {\displaystyle a\ \to \ \alpha } → β {\displaystyle a\ \to \ \beta } if we start with nonterminal symbol s {\displaystyle s} then we can use rule s → {\displaystyle s\ \to \ aa} turn s {\displaystyle s} into {\displaystyle aa} we can then apply one two later rules for example if we apply → β {\displaystyle a\ \to \ \beta } first {\displaystyle a} we get β {\displaystyle \beta a} if we then apply → α {\displaystyle a\ \to \ \alpha } second {\displaystyle a} we get β α {\displaystyle \beta \alpha } since both α {\displaystyle \alpha } β {\displaystyle \beta } are terminal symbols context-free grammars terminal symbols never appear on left hand side production rule there are no more rules that can be applied this same process can be used applying second two rules different orders order get all possible strings within our simple context-free grammar languages generated by context-free grammars are known context-free languages cfl different context-free grammars can generate same context-free language important distinguish properties language intrinsic properties from properties particular grammar extrinsic properties language equality question do two given context-free grammars generate same language undecidable context-free grammars arise linguistics where they are used describe structure sentences words natural language they were fact invented by linguist noam chomsky for this purpose but have not really lived up their original expectation by contrast computer science use recursively-defined concepts increased they were used more more early application grammars are used describe structure programming languages newer application they are used essential part extensible markup language xml called document type definition linguistics some authors use term phrase structure grammar refer context-free grammars whereby phrase-structure grammars are distinct from dependency grammars computer science popular notation for context-free grammars backus–naur form bnf contents background formal definitions o production rule notation o rule application o repetitive rule application o context-free language o proper cfgs o example examples o well-formed parentheses o well-formed nested parentheses square brackets o regular grammar o matching pairs o algebraic expressions o further examples + example + example + other examples o derivations syntax trees normal forms closure properties decidable problems undecidable problems o universality o language equality o language inclusion o being lower higher level chomsky hierarchy o grammar ambiguity o language disjointness extensions subclasses linguistic applications see also o parsing algorithms notes references external links background since time pāṇini at least linguists have described grammars languages terms their block structure described how sentences are recursively built up from smaller phrases eventually individual words word elements essential property these block structures that logical units never overlap for example sentence john whose blue car was garage walked grocery store can be logically parenthesized follows john whose blue car was garage walked grocery store context-free grammar provides simple mathematically precise mechanism for describing methods by which phrases some natural language are built from smaller blocks capturing block structure sentences natural way its simplicity makes formalism amenable rigorous mathematical study important features natural language syntax such agreement reference are not part context-free grammar but basic recursive structure sentences way which clauses nest inside other clauses way which lists adjectives adverbs are swallowed by nouns verbs described exactly formalism context-free grammars was developed mid-1950s by noam chomsky also their classification special type formal grammar which he called phrase-structure grammars what chomsky called phrase structure grammar also known now constituency grammar whereby constituency grammars stand contrast dependency grammars chomsky's generative grammar framework syntax natural language was described by context-free rules combined with transformation rules block structure was introduced into computer programming languages by algol project 1957–1960 which consequence also featured context-free grammar describe resulting algol syntax this became standard feature computer languages notation for grammars used concrete descriptions computer languages came be known backus–naur form after two members algol language design committee block structure aspect that context-free grammars capture so fundamental grammar that terms syntax grammar are often identified with context-free grammar rules especially computer science formal constraints not captured by grammar are then considered be part semantics language context-free grammars are simple enough allow construction efficient parsing algorithms which for given string determine whether how can be generated from grammar earley parser example such algorithm while widely used lr ll parsers are simpler algorithms that deal only with more restrictive subsets context-free grammars formal definitions context-free grammar g defined by 4-tuple g = v σ r s {\displaystyle g=v\sigma rs} where v finite set each element v ∈ v {\displaystyle v\in v} called nonterminal character variable each variable represents different type phrase clause sentence variables are also sometimes called syntactic categories each variable defines sub-language language defined by g σ finite set terminals disjoint from v which make up actual content sentence set terminals alphabet language defined by grammar g r finite relation from v v ∪ σ ∗ {\displaystyle v\cup \sigma ^{}} where asterisk represents kleene star operation members r are called rewrite rules productions grammar also commonly symbolized by p s start variable start symbol used represent whole sentence program must be element v production rule notation production rule r formalized mathematically pair α β ∈ r {\displaystyle \alpha \beta \in r} where α ∈ v {\displaystyle \alpha \in v} nonterminal β ∈ v ∪ σ ∗ {\displaystyle \beta \in v\cup \sigma ^{}} string variables and/or terminals rather than using ordered pair notation production rules are usually written using arrow operator with α its left hand side β its right hand side α → β {\displaystyle \alpha \rightarrow \beta } allowed for β be empty string this case customary denote by ε form α → ε {\displaystyle \alpha \rightarrow \varepsilon } called ε -production common list all right-hand sides for same left-hand side on same line using | pipe symbol separate them rules α → β {\displaystyle \alpha \rightarrow \beta {1}} α → β {\displaystyle \alpha \rightarrow \beta {2}} can hence be written α → β ∣ β {\displaystyle \alpha \rightarrow \beta {1}\mid \beta {2}} this case β {\displaystyle \beta {1}} β {\displaystyle \beta {2}} called first second alternative respectively rule application for any strings u v ∈ v ∪ σ ∗ {\displaystyle uv\in v\cup \sigma ^{}} we say u directly yields v written u ⇒ v {\displaystyle u\rightarrow v\} if ∃ α β ∈ r {\displaystyle \exists \alpha \beta \in r} with α ∈ v {\displaystyle \alpha \in v} u u ∈ v ∪ σ ∗ {\displaystyle u{1}u{2}\in v\cup \sigma ^{}} such that u = u α u {\displaystyle u\=u{1}\alpha u{2}} v = u β u {\displaystyle v\=u{1}\beta u{2}} thus v result applying rule α β {\displaystyle \alpha \beta } u repetitive rule application for any strings u v ∈ v ∪ σ ∗ {\displaystyle uv\in v\cup \sigma ^{}} we say u yields v written u ⇒ ∗ v {\displaystyle u{\stackrel {}{\rightarrow }}v} u ⇒⇒ v {\displaystyle u\rightarrow \rightarrow v\} some textbooks if ∃ k ≥ ∃ u ⋯ u k ∈ v ∪ σ ∗ {\displaystyle \exists k\geq 1\\exists \u{1}\cdots u{k}\in v\cup \sigma ^{}} such that u = u ⇒ u ⇒ ⋯ ⇒ u k = v {\displaystyle u=\u{1}\rightarrow u{2}\rightarrow \cdots \rightarrow u{k}\=v} this case if k ≥ {\displaystyle k\geq 2} ie u ≠ v {\displaystyle u\neq v} relation u ⇒ + v {\displaystyle u{\stackrel {+}{\rightarrow }}v} holds other words ⇒ ∗ {\displaystyle {\stackrel {}{\rightarrow }}} ⇒ + {\displaystyle {\stackrel {+}{\rightarrow }}} are reflexive transitive closure allowing word yield itself transitive closure requiring at least one step ⇒ {\displaystyle \rightarrow } respectively context-free language language grammar g = v σ r s {\displaystyle g=v\sigma rs} set l g = { w ∈ σ ∗ s ⇒ ∗ w } {\displaystyle lg=\{w\in \sigma ^{}s{\stackrel {}{\rightarrow }}w\}} language l said be context-free language cfl if there exists cfg g such that l = l g {\displaystyle l\=\lg} proper cfgs context-free grammar said be proper if has no unreachable symbols ∀ n ∈ v ∃ α β ∈ v ∪ σ ∗ s ⇒ ∗ α n β {\displaystyle \forall n\in v\exists \alpha \beta \in v\cup \sigma ^{}s{\stackrel {}{\rightarrow }}\alpha {n}\beta } no unproductive symbols ∀ n ∈ v ∃ w ∈ σ ∗ n ⇒ ∗ w {\displaystyle \forall n\in v\exists w\in \sigma ^{}n{\stackrel {}{\rightarrow }}w} no ε-productions ¬ ∃ n ∈ v n ε ∈ r {\displaystyle \neg \exists n\in vn\varepsilon \in r} no cycles ¬ ∃ n ∈ v n ⇒ + n {\displaystyle \neg \exists n\in vn{\stackrel {+}{\rightarrow }}n} every context-free grammar can be effectively transformed into weakly equivalent one without unreachable symbols weakly equivalent one without unproductive symbols weakly equivalent one without cycles every context-free grammar not producing ε can be effectively transformed into weakly equivalent one without ε-productions altogether every such grammar can be effectively transformed into weakly equivalent proper cfg example grammar g = { s } { b } p s {\displaystyle g=\{s\}\{ab\}ps} with productions s → asa s → bsb s → ε context-free not proper since includes ε-production typical derivation this grammar s → asa → aasaa → aabsbaa → aabbaa this makes clear that l g = { w w r w ∈ { b } ∗ } {\displaystyle lg=\{ww^{r}w\in \{ab\}^{}\}} language context-free however can be proved that not regular examples this section does not cite any sources please help improve this section by adding citations reliable sources unsourced material may be challenged removed june learn how when remove this template message well-formed parentheses canonical example context free grammar parenthesis matching which representative general case there are two terminal symbols one nonterminal symbol s production rules are s → ss s → s s → first rule allows s symbol multiply second rule allows s symbol become enclosed by matching parentheses third rule terminates recursion well-formed nested parentheses square brackets second canonical example two different kinds matching nested parentheses described by productions s → ss s → s → s s → s → with terminal symbols nonterminal s following sequence can be derived that grammar ] ] ] however there no context-free grammar for generating all sequences two different types parentheses each separately balanced disregarding other but where two types need not nest inside one another for example ] ] ] ] ] regular grammar every regular grammar context-free but not all context-free grammars are regular following context-free grammar however also regular s → s → s → bs terminals here are b while only nonterminal s language described all nonempty strings {\displaystyle a} s b {\displaystyle b} s that end {\displaystyle a} this grammar regular no rule has more than one nonterminal its right-hand side each these nonterminals at same end right-hand side every regular grammar corresponds directly nondeterministic finite automaton so we know that this regular language using pipe symbols grammar above can be described more tersely follows s → | | bs matching pairs context-free grammar we can pair up characters way we do with brackets simplest example s → asb s → ab this grammar generates language { n b n n ≥ } {\displaystyle \{a^{n}b^{n}n\geq 1\}} which not regular according pumping lemma for regular languages special character ε stands for empty string by changing above grammar s → asb | ε we obtain grammar generating language { n b n n ≥ } {\displaystyle \{a^{n}b^{n}n\geq 0\}} instead this differs only that contains empty string while original grammar did not algebraic expressions here context-free grammar for syntactically correct infix algebraic expressions variables x y z s → x s → y s → z s → s + s s → s - s s → s s s → s / s s → s this grammar can for example generate string x + y x - z y / x + x follows s start symbol → s - s by rule → s s - s by rule applied leftmost s → s s - s / s by rule applied rightmost s → s s - s / s by rule applied leftmost s → s s - s / s by rule applied rightmost s → s + s s - s / s etc → s + s s - s s / s → s + s s - s s / s + s → x + s s - s s / s + s → x + y s - s s / s + s → x + y x - s y / s + s → x + y x - s y / x + s → x + y x - z y / x + s → x + y x - z y / x + x note that many choices were made underway which rewrite was going be performed next these choices look quite arbitrary matter fact they are sense that string finally generated always same for example second third rewrites → s s - s by rule applied leftmost s → s s - s / s by rule applied rightmost s could be done opposite order → s - s / s by rule applied rightmost s → s s - s / s by rule applied leftmost s also many choices were made on which rule apply each selected s changing choices made not only order they were made usually affects which terminal string comes out at end let's look at this more detail consider parse tree this derivation s | /|\ s - s / \ /|\ /|\ s s s / s / | | \ /|\ x /|\ /|\ s s s s / | | \ /|\ z y /|\ s + s s + s | | | | x y x x starting at top step by step s tree expanded until no more unexpanded ses nonterminals remain picking different order expansion will produce different derivation but same parse tree parse tree will only change if we pick different rule apply at some position tree but can different parse tree still produce same terminal string which x + y x - z y / x + x this case yes for this particular grammar this possible grammars with this property are called ambiguous for example x + y z can be produced with these two different parse trees s s | | /|\ /|\ s s s + s / \ / \ /|\ z x /|\ s + s s s | | | | x y y z however language described by this grammar not inherently ambiguous alternative unambiguous grammar can be given for language for example t → x t → y t → z s → s + t s → s - t s → s t s → s / t t → s s → t once again picking s start symbol this alternative grammar will produce x + y z with parse tree similar left one above ie implicitly assuming association x + y z which not according standard operator precedence more elaborate unambiguous context-free grammars can be constructed that produce parse trees that obey all desired operator precedence associativity rules further examples example context-free grammar for language consisting all strings over {ab} containing unequal number a's b's s → u | v u → tau | tat | uat v → tbv | tbt | vbt t → atbt | btat | ε here nonterminal t can generate all strings with same number a's b's nonterminal u generates all strings with more a's than b's nonterminal v generates all strings with fewer a's than b's omitting third alternative rule for u v doesn't restrict grammar's language example another example non-regular language { b n m b n n ≥ m ≥ } {\displaystyle \{b^{n}a^{m}b^{2n}n\geq 0m\geq 0\}} context-free can be generated by following context-free grammar s → bsbb | → aa | ε other examples formation rules for terms formulas formal logic fit definition context-free grammar except that set symbols may be infinite there may be more than one start symbol derivations syntax trees derivation string for grammar sequence grammar rule applications that transforms start symbol into string derivation proves that string belongs grammar's language derivation fully determined by giving for each step rule applied that step occurrence its left hand side which applied for clarity intermediate string usually given well for instance with grammar s → s + s s → s → string + + can be derived with derivation s → rule on first s s+s → rule on second s s+s+s → rule on second s s+1+s → rule on third s s+1+a → rule on first s 1+1+a often strategy followed that deterministically determines next nonterminal rewrite leftmost derivation always leftmost nonterminal rightmost derivation always rightmost nonterminal given such strategy derivation completely determined by sequence rules applied for instance leftmost derivation s → rule on first s s+s → rule on first s 1+s → rule on first s 1+s+s → rule on first s 1+1+s → rule on first s 1+1+a can be summarized rule rule rule rule rule distinction between leftmost derivation rightmost derivation important because most parsers transformation input defined by giving piece code for every grammar rule that executed whenever rule applied therefore important know whether parser determines leftmost rightmost derivation because this determines order which pieces code will be executed see for example ll parsers lr parsers derivation also imposes some sense hierarchical structure on string that derived for example if string + + derived according leftmost derivation s → s + s → + s → + s + s → + + s → + + structure string would be { { }s + { { }s + { }s }s }s where { }s indicates substring recognized belonging s this hierarchy can also be seen tree s /|\ / | \ / | \ s '+' s | /|\ | / | \ '1' s '+' s | | '1' 'a' this tree called parse tree concrete syntax tree string by contrast with abstract syntax tree this case presented leftmost rightmost derivations define same parse tree however there another rightmost derivation same string s → s + s → s + → s + s + → s + + → + + this defines following parse tree s /|\ / | \ / | \ s '+' s /|\ | / | \ | s '+' s 'a' | | '1' '1' if for certain strings language grammar there more than one parsing tree then grammar said be ambiguous grammar such grammars are usually hard parse because parser cannot always decide which grammar rule has apply usually ambiguity feature grammar not language unambiguous grammar can be found that generates same context-free language however there are certain languages that can only be generated by ambiguous grammars such languages are called inherently ambiguous languages normal forms every context-free grammar that does not generate empty string can be transformed into one which there no ε-production that rule that has empty string product if grammar does generate empty string will be necessary include rule s → ϵ {\displaystyle s\rightarrow \epsilon } but there need be no other ε-rule every context-free grammar with no ε-production has equivalent grammar chomsky normal form greibach normal form equivalent here means that two grammars generate same language especially simple form production rules chomsky normal form grammars has both theoretical practical implications for instance given context-free grammar one can use chomsky normal form construct polynomial-time algorithm that decides whether given string language represented by that grammar not cyk algorithm closure properties context-free languages are closed under union concatenation kleene star substitution particular homomorphism inverse homomorphism intersection with regular language they are not closed under general intersection hence neither under complementation set difference decidable problems there are algorithms decide whether context-free language empty whether finite undecidable problems some questions that are undecidable for wider classes grammars become decidable for context-free grammars eg emptiness problem whether grammar generates any terminal strings at all undecidable for context-sensitive grammars but decidable for context-free grammars however many problems are undecidable even for context-free grammars examples are universality given cfg does generate language all strings over alphabet terminal symbols used its rules reduction can be demonstrated this problem from well-known undecidable problem determining whether turing machine accepts particular input halting problem reduction uses concept computation history string describing entire computation turing machine cfg can be constructed that generates all strings that are not accepting computation histories for particular turing machine on particular input thus will accept all strings only if machine doesn't accept that input language equality given two cfgs do they generate same language undecidability this problem direct consequence previous impossible even decide whether cfg equivalent trivial cfg defining language all strings language inclusion given two cfgs can first one generate all strings that second one can generate if this problem was decidable then language equality could be decided too two cfgs g1 g2 generate same language if lg1 subset lg2 lg2 subset lg1 being lower higher level chomsky hierarchy using greibach's theorem can be shown that two following problems are undecidable given context-sensitive grammar does describe context-free language given context-free grammar does describe regular language grammar ambiguity given cfg ambiguous undecidability this problem follows from fact that if algorithm determine ambiguity existed post correspondence problem could be decided which known be undecidable language disjointness given two cfgs there any string derivable from both grammars if this problem was decidable undecidable post correspondence problem could be decided too given strings α … α n β … β n {\displaystyle \alpha {1}\ldots \alpha {n}\beta {1}\ldots \beta {n}} over some alphabet { … k } {\displaystyle \{a{1}\ldots a{k}\}} let grammar g {\displaystyle g{1}} consist rule s → α s β r e v | ⋯ | α n s β n r e v | b {\displaystyle s\to \alpha {1}s\beta {1}^{rev}|\cdots |\alpha {n}s\beta {n}^{rev}|b} where β i r e v {\displaystyle \beta {i}^{rev}} denotes reversed string β i {\displaystyle \beta {i}} b {\displaystyle b} doesn't occur among i {\displaystyle a{i}} let grammar g {\displaystyle g{2}} consist rule t → t | ⋯ | k t k | b {\displaystyle t\to a{1}ta{1}|\cdots |a{k}ta{k}|b} then post problem given by α … α n β … β n {\displaystyle \alpha {1}\ldots \alpha {n}\beta {1}\ldots \beta {n}} has solution if only if l g {\displaystyle lg{1}} l g {\displaystyle lg{2}} share derivable string extensions obvious way extend context-free grammar formalism allow nonterminals have arguments values which are passed along within rules this allows natural language features such agreement reference programming language analogs such correct use definition identifiers be expressed natural way eg we can now easily express that english sentences subject verb must agree number computer science examples this approach include affix grammars attribute grammars indexed grammars van wijngaarden two-level grammars similar extensions exist linguistics extended context-free grammar regular right part grammar one which right-hand side production rules allowed be regular expression over grammar's terminals nonterminals extended context-free grammars describe exactly context-free languages another extension allow additional terminal symbols appear at left hand side rules constraining their application this produces formalism context-sensitive grammars subclasses there are number important subclasses context-free grammars lrk grammars also known deterministic context-free grammars allow parsing string recognition with deterministic pushdown automata pda but they can only describe deterministic context-free languages simple lr look-ahead lr grammars are subclasses that allow further simplification parsing slr lalr are recognized using same pda lr but with simpler tables most cases llk ll grammars allow parsing by direct construction leftmost derivation described above describe even fewer languages simple grammars are subclass ll1 grammars mostly interesting for its theoretical property that language equality simple grammars decidable while language inclusion not bracketed grammars have property that terminal symbols are divided into left right bracket pairs that always match up rules linear grammars have no rules with more than one nonterminal right hand side regular grammars are subclass linear grammars describe regular languages ie they correspond finite automata regular expressions lr parsing extends ll parsing support larger range grammars turn generalized lr parsing extends lr parsing support arbitrary context-free grammars on ll grammars lr grammars essentially performs ll parsing lr parsing respectively while on nondeterministic grammars efficient can be expected although glr parsing was developed 1980s many new language definitions parser generators continue be based on ll lalr lr parsing up present day linguistic applications chomsky initially hoped overcome limitations context-free grammars by adding transformation rules such rules are another standard device traditional linguistics eg passivization english much generative grammar has been devoted finding ways refining descriptive mechanisms phrase-structure grammar transformation rules such that exactly kinds things can be expressed that natural language actually allows allowing arbitrary transformations doesn't meet that goal they are much too powerful being turing complete unless significant restrictions are added eg no transformations that introduce then rewrite symbols context-free fashion chomsky's general position regarding non-context-freeness natural language has held up since then although his specific examples regarding inadequacy context-free grammars terms their weak generative capacity were later disproved gerald gazdar geoffrey pullum have argued that despite few non-context-free constructions natural language such cross-serial dependencies swiss german reduplication bambara vast majority forms natural language are indeed context-free see also parsing expression grammar stochastic context-free grammar algorithms for context-free grammar generation pumping lemma for context-free languages parsing algorithms cyk algorithm glr parser ll parser earley algorithm notes stephen scheinberg note on boolean properties context free languages information control 372–375 introduction automata theory languages computation john e hopcroft rajeen motwani jeffrey d ullman addison wesley p191 b hopcroft & ullman p b chomsky noam sep three models for description language pdf information theory ieee transactions 113–124 doi 101109/tit19561056813 archived from original pdf on retrieved notation here that sipser p hopcroft & ullman p define context-free grammars 4-tuples same way but with different variable names hopcroft & ullman pp 90–92 nijholt anton context-free grammars covers normal forms parsing lecture notes computer science springer p isbn 3-540-10245-0 mr hopcroft & ullman p88 lemma hopcroft & ullman p89 lemma this consequence unit-production elimination theorem hopcroft & ullman p91 theorem hopcroft & ullman p91 theorem hopcroft & ullman p131 theorem hopcroft & ullman p131-132 theorem hopcroft & ullman p132-134 theorem hopcroft & ullman p135-136 theorem hopcroft & ullman p134-135 theorem hopcroft & ullman p137-138 theorem sipser theorem p b c d hopcroft & ullman p b c hazewinkel michiel encyclopaedia mathematics updated annotated translation soviet mathematical encyclopaedia springer vol iv p isbn 978-1-55608-003-6 norvell theodore short introduction regular expressions context-free grammars pdf p retrieved august b shieber stuart evidence against context-freeness natural language pdf linguistics philosophy 333–343 doi 101007/bf00630917 b pullum geoffrey k gerald gazdar natural languages context-free languages linguistics philosophy 471–504 doi101007/bf00360802 culy christopher complexity vocabulary bambara linguistics philosophy 345–351 doi 101007/bf00630918 references hopcroft john e ullman jeffrey d introduction automata theory languages computation addison-wesley chapter context-free grammars pp 77–106 chapter properties context-free languages pp 125–137 sipser michael introduction theory computation pws publishing isbn 0-534-94728-x chapter context-free grammars pp 91–122 section decidable problems concerning context-free languages pp 156–159 section reductions via computation histories pp 176–183 j berstel l boasson jan van leeuwen ed context-free languages handbook theoretical computer science b elsevier pp 59–102 external links computer programmers may find stack exchange answer be useful non-computer programmers will find more academic introductory materials be enlightening v t e automata theory formal languages formal grammars chomsky hierarchy grammars languages abstract machines type-0 — type-1 — — — — — type-2 — — type-3 — — unrestricted no common name context-sensitive positive range concatenation indexed — linear context-free rewriting systems tree-adjoining context-free deterministic context-free visibly pushdown regular — non-recursive recursively enumerable decidable context-sensitive positive range concatenation indexed — linear context-free rewriting language tree-adjoining context-free deterministic context-free visibly pushdown regular star-free finite turing machine decider linear-bounded ptime turing machine nested stack thread automaton restricted tree stack automaton embedded pushdown nondeterministic pushdown deterministic pushdown visibly pushdown finite counter-free with aperiodic finite monoid acyclic finite each category languages except those marked by proper subset category directly above any language each category generated by grammar by automaton category same line retrieved from https//enwikipediaorg/w/indexphptitle=context-freegrammar&oldid=752183358 categories computer science compiler construction formal languages programming language topics hidden categories articles needing additional references from february all articles needing additional references articles needing additional references from june wikipedia articles with ascii art navigation menu personal tools not logged talk contributions create account log namespaces article talk variants views read edit view history more search navigation main page contents featured content current events random article donate wikipedia wikipedia store interaction help about wikipedia community portal recent changes contact page tools what links here related changes upload file special pages permanent link page information wikidata item cite this page print/export create book download pdf printable version languages বাংলা català čeština deutsch español فارسی français galego 한국어 hrvatski italiano עברית magyar македонски മലയാളം nederlands 日本語 norsk bokmål polski português русский slovenčina српски / srpski srpskohrvatski / српскохрватски suomi svenska தமிழ் українська 中文 edit links this page was last modified on november at text available under creative commons attribution-sharealike license additional terms may apply by using this site you agree terms use privacy policy wikipedia® registered trademark wikimedia foundation inc non-profit organization privacy policy about wikipedia disclaimers contact wikipedia developers cookie statement mobile view 